快速开始
=======================
推荐所有用户在运行测试案例前，了解Spike-Zoo的代码核心框架：

- ``Dataset:`` 定义不同数据集统一的接口，包含获取脉冲输入和清晰图数据等代码。
- ``Model:`` 对脉冲重构网络进行封装，包含脉冲输入处理、算法构建以及重构图像后处理等代码。
- ``Pipeline:`` 对数据和模型进行封装，包含推理过程中指标计算、图像保存以及模型训练等代码。

Spike-Zoo的代码框架与 `NeRFStudio <https://docs.nerf.studio/index.html>`_ 类似，
由 ``Pipeline`` 对 ``Model`` 和 ``Dataset`` 进行封装，并包含训练和推理功能。


.. raw:: html

   <div style="text-align: center;">
   
.. image:: imgs/pipeline.png
   :width: 450px

.. raw:: html

   </div>

代码目录如下：

.. code-block:: txt

    spikezoo
    ├── archs     # 网络架构
    ├── models    # 模型构建（对网络的输入输出进行封装）
    ├── data      # 数据集原始数据
    ├── datasets  # 数据集构建（对数据输出进行封装）
    ├── pipeline  # 管线定义代码（对模型和数据进行封装）
    ├── metrics   # 指标计算代码
    └── utils     # 辅助函数代码

Spike-Zoo 在构建类时采用了 **参数配置和实例化** 的方式，即通过定义一个配置类 ``MyClassConfig`` 来集中管理类的配置参数。
该配置类使用 ``@dataclass`` 装饰器自动生成构造函数，并将配置作为参数传递给目标类 ``MyClass`` 进行实例化。

.. code-block:: python

    from dataclasses import dataclass
    # config definition
    @dataclass
    class MyClassConfig:
        name: str = "myclass"
    # class definition
    class MyClass:
        def __init__(self,cfg:MyClassConfig):
            self.cfg = cfg
    config = MyClassConfig()
    cls = MyClass(config)

推理
----------------
管线构建
^^^^^^^^^^^

在推理阶段，Spike-Zoo提供 **单一模型管线** 和 **集成模型管线** 两种构建方式，其中集成模型管线在推理时会将多个模型串行推理，方便对比不同模型的性能。

**单一模型管线构建：**

.. code-block:: python

    from spikezoo.pipeline import Pipeline, PipelineConfig
    import spikezoo as sz
    pipeline = Pipeline(
        cfg=PipelineConfig(save_folder="results",version="v023"),
        model_cfg=sz.METHOD.BASE,
        dataset_cfg=sz.DATASET.BASE 
    )

``Pipeline`` 的构建包含 ``pipeline_cfg``, ``model_cfg`` 和 ``dataset_cfg`` 三部分。

- ``pipeline_cfg`` 指定了管线参数，设置了结果保存的路径，以及加载预训练模型的版本。

- ``model_cfg`` 指定了需要加载的模型参数。

- ``dataset_cfg`` 指定了需要加载的数据集参数。

关于管线参数配置的详细信息，可以参考 :ref:`eval_config` 了解。这里 ``model_cfg`` 和 ``dataset_cfg`` 均提供两种加载方式，一种方式是如例子所示直接输入方法名称，另一种方法是输入模型或者数据集的参数配置，可以参考 :ref:`eval_initial` 了解。


**集成模型管线构建：**

.. code-block:: python

    import spikezoo as sz
    from spikezoo.pipeline import EnsemblePipeline, EnsemblePipelineConfig
    pipeline = EnsemblePipeline(
        cfg=EnsemblePipelineConfig(save_folder="results",version="v023"),
        model_cfg_list=[
            sz.METHOD.BASE,sz.METHOD.TFP,sz.METHOD.TFI,sz.METHOD.SPK2IMGNET,sz.METHOD.WGSE,
            sz.METHOD.SSML,sz.METHOD.BSF,sz.METHOD.STIR,sz.METHOD.SPIKECLIP,sz.METHOD.SSIR],
        dataset_cfg=sz.DATASET.BASE,
    )

- ``model_cfg_list`` 指定了需要加载的模型参数的列表。



功能
^^^^^^^^^^^^

单一模型管线和集成模型管线仅在管线构建上有所不同，所对应的功能完全一致，如下：

- **I-单段脉冲重构:** 针对单段输入脉冲，进行图像重构、保存图片并计算重构图像的性能指标。

我们提供三种接口来获取单段脉冲流：

.. code-block:: python

    # 1. 从数据集中获取（默认对应的测试集），结果保存在 infer_from_dataset 文件夹下。
    pipeline.infer_from_dataset(idx=0)
    # 2. 从给定的 .dat 文件中获取，结果保存在 infer_from_file 文件夹下。
    pipeline.infer_from_file(file_path='data/scissor.dat', width=400, height=250)
    # 3. 直接给定输入脉冲，结果保存在 infer_from_spk 文件夹下。
    spike = sz.load_vidar_dat("data/scissor.dat", width=400, height=250)
    pipeline.infer_from_spk(spike)


- **II-数据集重构可视化:** 保存给定数据集的所有图片（默认对应的测试集）

.. code-block:: python

    # 结果保存在 infer_from_dataset 文件夹下。
    pipeline.save_imgs_from_dataset()

- **III-数据集指标计算:** 计算在给定数据集的指标（默认对应的测试集）

.. code-block:: python

    #  结果保存在 result.log 下。
    pipeline.cal_metrics()

- **IV-参数值计算:** 计算模型大小、计算复杂度以及推理平均时间

.. code-block:: python

    #  结果保存在 result.log 下。
    pipeline.cal_params()


训练
----------------

训练管线的构建和推理管线逻辑保持一致。这里，我们使用BASE网络在REDS_BASE数据集上进行训练：

.. code-block:: python

    from spikezoo.pipeline import TrainPipelineConfig, TrainPipeline
    from spikezoo.datasets.reds_base_dataset import REDS_BASEConfig
    from spikezoo.models.base_model import BaseModelConfig
    pipeline = TrainPipeline(
        cfg=TrainPipelineConfig(save_folder="results", epochs = 10),
        dataset_cfg=REDS_BASEConfig(root_dir = "spikezoo/data/REDS_BASE"),
        model_cfg=BaseModelConfig(),
    )
    pipeline.train()

.. note::

    我们在单卡4090 GPU上用2分钟完成了训练，PSNR达到了32.8dB，SSIM达到了0.92。



模型基本用法
----------------

除了通过上述方式利用管线对模型进行调用以外，也提供直接构建模型的方式：

.. code-block:: python

    import spikezoo as sz
    from spikezoo.models.base_model import BaseModel, BaseModelConfig
    # input data
    spike = sz.load_vidar_dat("data/data.dat", width=400, height=250, out_format="tensor")
    spike = spike[None].cuda()
    print(f"Input spike shape: {spike.shape}")
    # net
    net = BaseModel(BaseModelConfig(model_params={"inDim": 41}))
    net.build_network(mode = "debug")
    # process
    recon_img = net(spike)
    print(recon_img.shape,recon_img.max(),recon_img.min())

更多用法参考 :ref:`model_use` 。

